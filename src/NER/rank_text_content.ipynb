{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Text Content by Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted = pd.read_csv('df_extracted.csv', engine='python', encoding='utf-8', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>18977.000000</td>\n",
       "      <td>18977.000000</td>\n",
       "      <td>1.897700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>9488.000000</td>\n",
       "      <td>11927.675344</td>\n",
       "      <td>9.184705e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5478.332365</td>\n",
       "      <td>6883.190923</td>\n",
       "      <td>1.599096e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.010000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4744.000000</td>\n",
       "      <td>5946.000000</td>\n",
       "      <td>1.025200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>9488.000000</td>\n",
       "      <td>11961.000000</td>\n",
       "      <td>2.830500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>14232.000000</td>\n",
       "      <td>17885.000000</td>\n",
       "      <td>1.055390e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>18976.000000</td>\n",
       "      <td>23795.000000</td>\n",
       "      <td>2.708538e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1         count\n",
       "count  18977.000000  18977.000000  1.897700e+04\n",
       "mean    9488.000000  11927.675344  9.184705e+04\n",
       "std     5478.332365   6883.190923  1.599096e+05\n",
       "min        0.000000      0.000000  1.010000e+02\n",
       "25%     4744.000000   5946.000000  1.025200e+04\n",
       "50%     9488.000000  11961.000000  2.830500e+04\n",
       "75%    14232.000000  17885.000000  1.055390e+05\n",
       "max    18976.000000  23795.000000  2.708538e+06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracted.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>file_name</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>count</th>\n",
       "      <th>similarity_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OLVEA - OLVEAct Now Report - EN - 2019-20.pdf</td>\n",
       "      <td>corporate social responsibility performance re...</td>\n",
       "      <td>29122</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20150416_COP_N°5_EN.pdf</td>\n",
       "      <td>sustainable development the energy that fuels ...</td>\n",
       "      <td>11939</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017_report_-_FINAL__UNLOCKED.pdf</td>\n",
       "      <td>the whole or any part of this work may not be ...</td>\n",
       "      <td>226975</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>COP_Report_SMART_-_Apr_2013_final.pdf</td>\n",
       "      <td>ptsinarmasagro resources andtechnology tbkglob...</td>\n",
       "      <td>37025</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cop_ETS_2019.pdf</td>\n",
       "      <td>eser contracting and industry co. inc. communi...</td>\n",
       "      <td>35188</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                                      file_name  \\\n",
       "0           0             0  OLVEA - OLVEAct Now Report - EN - 2019-20.pdf   \n",
       "1           1             1                        20150416_COP_N°5_EN.pdf   \n",
       "2           2             2              2017_report_-_FINAL__UNLOCKED.pdf   \n",
       "3           3             3          COP_Report_SMART_-_Apr_2013_final.pdf   \n",
       "4           4             4                               cop_ETS_2019.pdf   \n",
       "\n",
       "                                          clean_text   count  \\\n",
       "0  corporate social responsibility performance re...   29122   \n",
       "1  sustainable development the energy that fuels ...   11939   \n",
       "2  the whole or any part of this work may not be ...  226975   \n",
       "3  ptsinarmasagro resources andtechnology tbkglob...   37025   \n",
       "4  eser contracting and industry co. inc. communi...   35188   \n",
       "\n",
       "                                    similarity_index  \n",
       "0    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "1    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "2    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "3    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "4    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracted_sample = df_extracted[:5]\n",
    "df_extracted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\ohike\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\ohike\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\ohike\\appdata\\roaming\\python\\python37\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ohike\\appdata\\roaming\\python\\python37\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\ohike\\appdata\\roaming\\python\\python37\\site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\ohike\\appdata\\roaming\\python\\python37\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\ohike\\appdata\\roaming\\python\\python37\\site-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install gensim\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document: a piece of text, in the form of a string. This could be just a few words, or a whole novel.  \n",
    "Corpus: a collection of documents.  \n",
    "Term: a word in a document.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ohike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ohike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ohike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords list\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface lemma tokenizer from nltk with sklearn\n",
    "class LemmaTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the stop words\n",
    "tokenizer=LemmaTokenizer()\n",
    "token_stop = tokenizer(' '.join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = ['conflict', 'violence', 'displacement', 'drought', 'earthquake', 'fire', 'flooding', 'freeze', 'health emergency', 'dengue', 'pneumonic plague', 'measles', 'landslide', 'tropical storm', 'typhoon', 'cyclone', 'hurricane', 'tsunami', 'urban disaster', 'volcanic eruption', 'refugee', 'terrorist attack', 'cold wave', 'complex emergency', 'epidemic', 'extratropical cyclone', 'flash flood', 'flood', 'heat wave', 'insect infestation', 'land slide', 'mud slide','snow avalanche', 'storm surge', 'technological disaster', 'tropical cyclone', 'volcano', 'wild fire', 'flood crisis', 'explosion', 'affected tornado', 'affected', 'death toll', 'tornado relief', 'flood appeal', 'massive explosion', 'affected areas', 'praying victims', 'injured', 'lurches fire', 'flood relief', 'flood affected', 'tornado victims', 'deadly', 'evacuated', 'relief', 'flood death', 'deaths confirmed', 'affected flooding', 'people killed', 'flood damage', 'people dead', 'major flood', 'rubble', 'another explosion', 'flood warnings', 'tornado survivor', 'damage', 'devastating', 'flood toll', 'affected hurricane', 'crisis', 'relief efforts', 'flood emergency', 'fire flood', 'huge explosion', 'bushfire', 'torrential rains', 'affected explosion', 'disaster', 'twister', 'blast', 'injuries reported', 'fatalities', 'large explosion', 'destroyed', 'displaced', 'casualties', 'climate change', 'major explosion', 'response disasters', 'explosion victims', 'tragic', 'dealing hurricane', 'flood recovery', 'dead torrential', 'flood years', 'massive tornado', 'buried alive', 'alive rubble', 'crisis rises', 'flood ravaged', 'killed injured', 'killed people', 'people died', 'floods kill', 'tornado damage', 'facing flood', 'deadly explosion', 'flood disaster', 'tornado disaster', 'help victims', 'hundreds homes', 'severe flooding', 'magnitude', 'firefighters police', 'fire explosion', 'storm', 'flood hits', 'floodwaters', 'emergency', 'flood alerts', 'crisis unfolds', 'tragic events', 'deadly tornado', 'people trapped', 'surging floods', 'city tornado', 'damaged hurricane', 'rains severely', 'house flood', 'devastating tornado', 'lost lives', 'reportedly dead', 'following explosion', 'tornado flood', 'early warninig', 'warning', 'dead floods', 'flood threat', 'flood situation', 'risk running', 'loss life', 'thoughts victims', 'terrible explosion', 'seismic', 'flood homeowners', 'flood claims', 'power supplies', 'free hotline', 'hotline help', 'registered magnitude', 'prepare hurricane', 'landfall', 'crisis worsens', 'communities damaged', 'destruction', 'tornado', 'hurricane coming', 'toxins flood', 'release toxins', 'toxins', 'supplies waters', 'crisis found', 'braces major', 'government negligent', 'attack', 'waiting hurricane', 'terror', 'memorial service', 'terror attack', 'coast hurricane', 'terrified hurricane', 'hurricane category', 'disaster relief', 'cleanup', 'troops lend', 'effected hurricane', 'time hurricane', 'saying hurricane', 'praying families', 'dramatic', 'path hurricane']\n",
    "search_term_dic = {i: search_term[i] for i in range(len(search_term))}\n",
    "search_term = search_term_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english', ngram_range = (1, 4),\n",
    "                             max_df = .75, min_df = 1, max_features = 100000)\n",
    "vectorizer.fit(search_term.values())\n",
    "\n",
    "M = vectorizer.fit_transform(df_extracted['clean_text'])\n",
    "\n",
    "df_keywords = pd.DataFrame(vectorizer.transform(search_term.values()).todense(),\n",
    "                          index = search_term.keys(),\n",
    "                          columns = vectorizer.get_feature_names())\n",
    "df_keywords.index.name = 'report'\n",
    "\n",
    "print('Shape:', df_keywords.shape)\n",
    "display(df_keywords.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('affected', 0),\n",
       " ('affected areas', 1),\n",
       " ('affected explosion', 2),\n",
       " ('affected flooding', 3),\n",
       " ('affected hurricane', 4),\n",
       " ('affected tornado', 5),\n",
       " ('alerts', 6),\n",
       " ('alive', 7),\n",
       " ('alive rubble', 8),\n",
       " ('appeal', 9),\n",
       " ('areas', 10),\n",
       " ('attack', 11),\n",
       " ('avalanche', 12),\n",
       " ('blast', 13),\n",
       " ('braces', 14),\n",
       " ('braces major', 15),\n",
       " ('buried', 16),\n",
       " ('buried alive', 17),\n",
       " ('bushfire', 18),\n",
       " ('casualties', 19),\n",
       " ('category', 20),\n",
       " ('change', 21),\n",
       " ('city', 22),\n",
       " ('city tornado', 23),\n",
       " ('claims', 24),\n",
       " ('cleanup', 25),\n",
       " ('climate', 26),\n",
       " ('climate change', 27),\n",
       " ('coast', 28),\n",
       " ('coast hurricane', 29),\n",
       " ('cold', 30),\n",
       " ('cold wave', 31),\n",
       " ('coming', 32),\n",
       " ('communities', 33),\n",
       " ('communities damaged', 34),\n",
       " ('complex', 35),\n",
       " ('complex emergency', 36),\n",
       " ('confirmed', 37),\n",
       " ('conflict', 38),\n",
       " ('crisis', 39),\n",
       " ('crisis rises', 40),\n",
       " ('crisis unfolds', 41),\n",
       " ('crisis worsens', 42),\n",
       " ('cyclone', 43),\n",
       " ('damage', 44),\n",
       " ('damaged', 45),\n",
       " ('damaged hurricane', 46),\n",
       " ('dead', 47),\n",
       " ('dead floods', 48),\n",
       " ('dead torrential', 49),\n",
       " ('deadly', 50),\n",
       " ('deadly explosion', 51),\n",
       " ('deadly tornado', 52),\n",
       " ('dealing', 53),\n",
       " ('dealing hurricane', 54),\n",
       " ('death', 55),\n",
       " ('death toll', 56),\n",
       " ('deaths', 57),\n",
       " ('deaths confirmed', 58),\n",
       " ('dengue', 59),\n",
       " ('destroyed', 60),\n",
       " ('destruction', 61),\n",
       " ('devastating', 62),\n",
       " ('devastating tornado', 63),\n",
       " ('died', 64),\n",
       " ('disaster', 65),\n",
       " ('disaster relief', 66),\n",
       " ('disasters', 67),\n",
       " ('displaced', 68),\n",
       " ('displacement', 69),\n",
       " ('dramatic', 70),\n",
       " ('drought', 71),\n",
       " ('early', 72),\n",
       " ('early warninig', 73),\n",
       " ('earthquake', 74),\n",
       " ('effected', 75),\n",
       " ('effected hurricane', 76),\n",
       " ('efforts', 77),\n",
       " ('emergency', 78),\n",
       " ('epidemic', 79),\n",
       " ('eruption', 80),\n",
       " ('evacuated', 81),\n",
       " ('events', 82),\n",
       " ('explosion', 83),\n",
       " ('explosion victims', 84),\n",
       " ('extratropical', 85),\n",
       " ('extratropical cyclone', 86),\n",
       " ('facing', 87),\n",
       " ('facing flood', 88),\n",
       " ('families', 89),\n",
       " ('fatalities', 90),\n",
       " ('firefighters', 91),\n",
       " ('firefighters police', 92),\n",
       " ('flash', 93),\n",
       " ('flash flood', 94),\n",
       " ('flood', 95),\n",
       " ('flood affected', 96),\n",
       " ('flood alerts', 97),\n",
       " ('flood appeal', 98),\n",
       " ('flood claims', 99),\n",
       " ('flood crisis', 100),\n",
       " ('flood damage', 101),\n",
       " ('flood death', 102),\n",
       " ('flood disaster', 103),\n",
       " ('flood emergency', 104),\n",
       " ('flood hits', 105),\n",
       " ('flood homeowners', 106),\n",
       " ('flood ravaged', 107),\n",
       " ('flood recovery', 108),\n",
       " ('flood relief', 109),\n",
       " ('flood situation', 110),\n",
       " ('flood threat', 111),\n",
       " ('flood toll', 112),\n",
       " ('flood warnings', 113),\n",
       " ('flood years', 114),\n",
       " ('flooding', 115),\n",
       " ('floods', 116),\n",
       " ('floods kill', 117),\n",
       " ('floodwaters', 118),\n",
       " ('following', 119),\n",
       " ('following explosion', 120),\n",
       " ('free', 121),\n",
       " ('free hotline', 122),\n",
       " ('freeze', 123),\n",
       " ('government', 124),\n",
       " ('government negligent', 125),\n",
       " ('health', 126),\n",
       " ('health emergency', 127),\n",
       " ('heat', 128),\n",
       " ('heat wave', 129),\n",
       " ('help', 130),\n",
       " ('help victims', 131),\n",
       " ('hits', 132),\n",
       " ('homeowners', 133),\n",
       " ('homes', 134),\n",
       " ('hotline', 135),\n",
       " ('hotline help', 136),\n",
       " ('house', 137),\n",
       " ('house flood', 138),\n",
       " ('huge', 139),\n",
       " ('huge explosion', 140),\n",
       " ('hundreds', 141),\n",
       " ('hundreds homes', 142),\n",
       " ('hurricane', 143),\n",
       " ('hurricane category', 144),\n",
       " ('hurricane coming', 145),\n",
       " ('infestation', 146),\n",
       " ('injured', 147),\n",
       " ('injuries', 148),\n",
       " ('injuries reported', 149),\n",
       " ('insect', 150),\n",
       " ('insect infestation', 151),\n",
       " ('kill', 152),\n",
       " ('killed', 153),\n",
       " ('killed injured', 154),\n",
       " ('killed people', 155),\n",
       " ('land', 156),\n",
       " ('land slide', 157),\n",
       " ('landfall', 158),\n",
       " ('landslide', 159),\n",
       " ('large', 160),\n",
       " ('large explosion', 161),\n",
       " ('lend', 162),\n",
       " ('life', 163),\n",
       " ('lives', 164),\n",
       " ('loss', 165),\n",
       " ('loss life', 166),\n",
       " ('lost', 167),\n",
       " ('lost lives', 168),\n",
       " ('lurches', 169),\n",
       " ('magnitude', 170),\n",
       " ('major', 171),\n",
       " ('major explosion', 172),\n",
       " ('major flood', 173),\n",
       " ('massive', 174),\n",
       " ('massive explosion', 175),\n",
       " ('massive tornado', 176),\n",
       " ('measles', 177),\n",
       " ('memorial', 178),\n",
       " ('memorial service', 179),\n",
       " ('mud', 180),\n",
       " ('mud slide', 181),\n",
       " ('negligent', 182),\n",
       " ('path', 183),\n",
       " ('path hurricane', 184),\n",
       " ('people', 185),\n",
       " ('people dead', 186),\n",
       " ('people died', 187),\n",
       " ('people killed', 188),\n",
       " ('people trapped', 189),\n",
       " ('plague', 190),\n",
       " ('pneumonic', 191),\n",
       " ('pneumonic plague', 192),\n",
       " ('police', 193),\n",
       " ('power', 194),\n",
       " ('power supplies', 195),\n",
       " ('praying', 196),\n",
       " ('praying families', 197),\n",
       " ('praying victims', 198),\n",
       " ('prepare', 199),\n",
       " ('prepare hurricane', 200),\n",
       " ('rains', 201),\n",
       " ('rains severely', 202),\n",
       " ('ravaged', 203),\n",
       " ('recovery', 204),\n",
       " ('refugee', 205),\n",
       " ('registered', 206),\n",
       " ('registered magnitude', 207),\n",
       " ('release', 208),\n",
       " ('release toxins', 209),\n",
       " ('relief', 210),\n",
       " ('relief efforts', 211),\n",
       " ('reported', 212),\n",
       " ('reportedly', 213),\n",
       " ('reportedly dead', 214),\n",
       " ('response', 215),\n",
       " ('response disasters', 216),\n",
       " ('rises', 217),\n",
       " ('risk', 218),\n",
       " ('risk running', 219),\n",
       " ('rubble', 220),\n",
       " ('running', 221),\n",
       " ('saying', 222),\n",
       " ('saying hurricane', 223),\n",
       " ('seismic', 224),\n",
       " ('service', 225),\n",
       " ('severe', 226),\n",
       " ('severe flooding', 227),\n",
       " ('severely', 228),\n",
       " ('situation', 229),\n",
       " ('slide', 230),\n",
       " ('snow', 231),\n",
       " ('snow avalanche', 232),\n",
       " ('storm', 233),\n",
       " ('storm surge', 234),\n",
       " ('supplies', 235),\n",
       " ('supplies waters', 236),\n",
       " ('surge', 237),\n",
       " ('surging', 238),\n",
       " ('surging floods', 239),\n",
       " ('survivor', 240),\n",
       " ('technological', 241),\n",
       " ('technological disaster', 242),\n",
       " ('terrible', 243),\n",
       " ('terrible explosion', 244),\n",
       " ('terrified', 245),\n",
       " ('terrified hurricane', 246),\n",
       " ('terror', 247),\n",
       " ('terror attack', 248),\n",
       " ('terrorist', 249),\n",
       " ('terrorist attack', 250),\n",
       " ('thoughts', 251),\n",
       " ('thoughts victims', 252),\n",
       " ('threat', 253),\n",
       " ('time', 254),\n",
       " ('time hurricane', 255),\n",
       " ('toll', 256),\n",
       " ('tornado', 257),\n",
       " ('tornado damage', 258),\n",
       " ('tornado disaster', 259),\n",
       " ('tornado flood', 260),\n",
       " ('tornado relief', 261),\n",
       " ('tornado survivor', 262),\n",
       " ('tornado victims', 263),\n",
       " ('torrential', 264),\n",
       " ('torrential rains', 265),\n",
       " ('toxins', 266),\n",
       " ('toxins flood', 267),\n",
       " ('tragic', 268),\n",
       " ('tragic events', 269),\n",
       " ('trapped', 270),\n",
       " ('troops', 271),\n",
       " ('troops lend', 272),\n",
       " ('tropical', 273),\n",
       " ('tropical cyclone', 274),\n",
       " ('tropical storm', 275),\n",
       " ('tsunami', 276),\n",
       " ('twister', 277),\n",
       " ('typhoon', 278),\n",
       " ('unfolds', 279),\n",
       " ('urban', 280),\n",
       " ('urban disaster', 281),\n",
       " ('victims', 282),\n",
       " ('violence', 283),\n",
       " ('volcanic', 284),\n",
       " ('volcanic eruption', 285),\n",
       " ('volcano', 286),\n",
       " ('waiting', 287),\n",
       " ('waiting hurricane', 288),\n",
       " ('warning', 289),\n",
       " ('warnings', 290),\n",
       " ('warninig', 291),\n",
       " ('waters', 292),\n",
       " ('wave', 293),\n",
       " ('wild', 294),\n",
       " ('worsens', 295),\n",
       " ('years', 296)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-86-4d90b535366c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mclean_text\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_extracted\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'clean_text'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mdoc_vectors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvectorizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'clean_text'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mcosine_similarities\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlinear_kernel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdoc_vectors\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdoc_vectors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1650\u001B[0m         \"\"\"\n\u001B[0;32m   1651\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1652\u001B[1;33m         \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mraw_documents\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1653\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tfidf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1654\u001B[0m         \u001B[1;31m# X is already a transformed view of raw_documents so\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1046\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mraw_documents\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1047\u001B[0m             raise ValueError(\n\u001B[1;32m-> 1048\u001B[1;33m                 \u001B[1;34m\"Iterable over raw text documents expected, \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1049\u001B[0m                 \"string object received.\")\n\u001B[0;32m   1050\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "#for i in range(len(df_extracted['clean_text'])):\n",
    "#    file_name = df_extracted['file_name'][i]\n",
    "#    clean_text = df_extracted['clean_text'][i]\n",
    "#    \n",
    "#    doc_vectors = vectorizer.fit_transform('clean_text')\n",
    "#    cosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
    "#\n",
    "#    df_extracted['similarity_index'][i] = cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-87-e73eba0796d6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdoc_vectors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvectorizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_extracted\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'clean_text'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mcosine_similarities\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlinear_kernel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdoc_vectors\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdoc_vectors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mdf_extracted\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'similarity_index'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcosine_similarities\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1650\u001B[0m         \"\"\"\n\u001B[0;32m   1651\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1652\u001B[1;33m         \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mraw_documents\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1653\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tfidf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1654\u001B[0m         \u001B[1;31m# X is already a transformed view of raw_documents so\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1056\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1057\u001B[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001B[1;32m-> 1058\u001B[1;33m                                           self.fixed_vocabulary_)\n\u001B[0m\u001B[0;32m   1059\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1060\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbinary\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36m_count_vocab\u001B[1;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[0;32m    972\u001B[0m                     \u001B[0mfeature_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvocabulary\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    973\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mfeature_idx\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfeature_counter\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 974\u001B[1;33m                         \u001B[0mfeature_counter\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature_idx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    975\u001B[0m                     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    976\u001B[0m                         \u001B[0mfeature_counter\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature_idx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#doc_vectors = vectorizer.fit_transform(df_extracted['clean_text'])\n",
    "#cosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
    "\n",
    "#df_extracted['similarity_index'] = cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity = pd.DataFrame(cosine_similarity(X = df_keywords.values, Y = M).T,\n",
    "                             columns = df_keywords.index.tolist())\n",
    "print('Shape:', df_similarity.shape)\n",
    "display(df_similarity.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>file_name</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>count</th>\n",
       "      <th>similarity_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OLVEA - OLVEAct Now Report - EN - 2019-20.pdf</td>\n",
       "      <td>corporate social responsibility performance re...</td>\n",
       "      <td>29122</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20150416_COP_N°5_EN.pdf</td>\n",
       "      <td>sustainable development the energy that fuels ...</td>\n",
       "      <td>11939</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017_report_-_FINAL__UNLOCKED.pdf</td>\n",
       "      <td>the whole or any part of this work may not be ...</td>\n",
       "      <td>226975</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>COP_Report_SMART_-_Apr_2013_final.pdf</td>\n",
       "      <td>ptsinarmasagro resources andtechnology tbkglob...</td>\n",
       "      <td>37025</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cop_ETS_2019.pdf</td>\n",
       "      <td>eser contracting and industry co. inc. communi...</td>\n",
       "      <td>35188</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18972</td>\n",
       "      <td>18972</td>\n",
       "      <td>23789</td>\n",
       "      <td>CSR_Report_2014.pdf</td>\n",
       "      <td>ah industries corporate social r esponsibility...</td>\n",
       "      <td>39306</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18973</td>\n",
       "      <td>18973</td>\n",
       "      <td>23792</td>\n",
       "      <td>Nilorngruppen_Sustainability_report.pdf</td>\n",
       "      <td>1more fit for the future sustainability report...</td>\n",
       "      <td>112118</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>23793</td>\n",
       "      <td>MM_CSR_2018.pdf</td>\n",
       "      <td>annual corporate social responsibility report ...</td>\n",
       "      <td>39360</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18975</td>\n",
       "      <td>18975</td>\n",
       "      <td>23794</td>\n",
       "      <td>AmatheonAgri-COP-2017.pdf</td>\n",
       "      <td>01amatheon agri communication on progress 2017...</td>\n",
       "      <td>21804</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18976</td>\n",
       "      <td>18976</td>\n",
       "      <td>23795</td>\n",
       "      <td>Letter_COP_CEO_Oct2014.pdf</td>\n",
       "      <td>24 th october 2014 to our stakeholders i am pl...</td>\n",
       "      <td>586</td>\n",
       "      <td>(0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18977 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  \\\n",
       "0               0             0   \n",
       "1               1             1   \n",
       "2               2             2   \n",
       "3               3             3   \n",
       "4               4             4   \n",
       "...           ...           ...   \n",
       "18972       18972         23789   \n",
       "18973       18973         23792   \n",
       "18974       18974         23793   \n",
       "18975       18975         23794   \n",
       "18976       18976         23795   \n",
       "\n",
       "                                           file_name  \\\n",
       "0      OLVEA - OLVEAct Now Report - EN - 2019-20.pdf   \n",
       "1                            20150416_COP_N°5_EN.pdf   \n",
       "2                  2017_report_-_FINAL__UNLOCKED.pdf   \n",
       "3              COP_Report_SMART_-_Apr_2013_final.pdf   \n",
       "4                                   cop_ETS_2019.pdf   \n",
       "...                                              ...   \n",
       "18972                            CSR_Report_2014.pdf   \n",
       "18973        Nilorngruppen_Sustainability_report.pdf   \n",
       "18974                                MM_CSR_2018.pdf   \n",
       "18975                      AmatheonAgri-COP-2017.pdf   \n",
       "18976                     Letter_COP_CEO_Oct2014.pdf   \n",
       "\n",
       "                                              clean_text   count  \\\n",
       "0      corporate social responsibility performance re...   29122   \n",
       "1      sustainable development the energy that fuels ...   11939   \n",
       "2      the whole or any part of this work may not be ...  226975   \n",
       "3      ptsinarmasagro resources andtechnology tbkglob...   37025   \n",
       "4      eser contracting and industry co. inc. communi...   35188   \n",
       "...                                                  ...     ...   \n",
       "18972  ah industries corporate social r esponsibility...   39306   \n",
       "18973  1more fit for the future sustainability report...  112118   \n",
       "18974  annual corporate social responsibility report ...   39360   \n",
       "18975  01amatheon agri communication on progress 2017...   21804   \n",
       "18976  24 th october 2014 to our stakeholders i am pl...     586   \n",
       "\n",
       "                                        similarity_index  \n",
       "0        (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "1        (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "2        (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "3        (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "4        (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "...                                                  ...  \n",
       "18972    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "18973    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "18974    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "18975    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "18976    (0, 615)\\t0.14519212172971319\\n  (0, 612)\\t0...  \n",
       "\n",
       "[18977 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted.to_csv('df_extracted_ranked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>file_name</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OLVEA - OLVEAct Now Report - EN - 2019-20.pdf</td>\n",
       "      <td>corporate social responsibility performance re...</td>\n",
       "      <td>29122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20150416_COP_N°5_EN.pdf</td>\n",
       "      <td>sustainable development the energy that fuels ...</td>\n",
       "      <td>11939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017_report_-_FINAL__UNLOCKED.pdf</td>\n",
       "      <td>the whole or any part of this work may not be ...</td>\n",
       "      <td>226975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>COP_Report_SMART_-_Apr_2013_final.pdf</td>\n",
       "      <td>ptsinarmasagro resources andtechnology tbkglob...</td>\n",
       "      <td>37025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>cop_ETS_2019.pdf</td>\n",
       "      <td>eser contracting and industry co. inc. communi...</td>\n",
       "      <td>35188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18972</td>\n",
       "      <td>18972</td>\n",
       "      <td>23789</td>\n",
       "      <td>CSR_Report_2014.pdf</td>\n",
       "      <td>ah industries corporate social r esponsibility...</td>\n",
       "      <td>39306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18973</td>\n",
       "      <td>18973</td>\n",
       "      <td>23792</td>\n",
       "      <td>Nilorngruppen_Sustainability_report.pdf</td>\n",
       "      <td>1more fit for the future sustainability report...</td>\n",
       "      <td>112118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>23793</td>\n",
       "      <td>MM_CSR_2018.pdf</td>\n",
       "      <td>annual corporate social responsibility report ...</td>\n",
       "      <td>39360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18975</td>\n",
       "      <td>18975</td>\n",
       "      <td>23794</td>\n",
       "      <td>AmatheonAgri-COP-2017.pdf</td>\n",
       "      <td>01amatheon agri communication on progress 2017...</td>\n",
       "      <td>21804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18976</td>\n",
       "      <td>18976</td>\n",
       "      <td>23795</td>\n",
       "      <td>Letter_COP_CEO_Oct2014.pdf</td>\n",
       "      <td>24 th october 2014 to our stakeholders i am pl...</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18977 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  \\\n",
       "0               0             0   \n",
       "1               1             1   \n",
       "2               2             2   \n",
       "3               3             3   \n",
       "4               4             4   \n",
       "...           ...           ...   \n",
       "18972       18972         23789   \n",
       "18973       18973         23792   \n",
       "18974       18974         23793   \n",
       "18975       18975         23794   \n",
       "18976       18976         23795   \n",
       "\n",
       "                                           file_name  \\\n",
       "0      OLVEA - OLVEAct Now Report - EN - 2019-20.pdf   \n",
       "1                            20150416_COP_N°5_EN.pdf   \n",
       "2                  2017_report_-_FINAL__UNLOCKED.pdf   \n",
       "3              COP_Report_SMART_-_Apr_2013_final.pdf   \n",
       "4                                   cop_ETS_2019.pdf   \n",
       "...                                              ...   \n",
       "18972                            CSR_Report_2014.pdf   \n",
       "18973        Nilorngruppen_Sustainability_report.pdf   \n",
       "18974                                MM_CSR_2018.pdf   \n",
       "18975                      AmatheonAgri-COP-2017.pdf   \n",
       "18976                     Letter_COP_CEO_Oct2014.pdf   \n",
       "\n",
       "                                              clean_text   count  \n",
       "0      corporate social responsibility performance re...   29122  \n",
       "1      sustainable development the energy that fuels ...   11939  \n",
       "2      the whole or any part of this work may not be ...  226975  \n",
       "3      ptsinarmasagro resources andtechnology tbkglob...   37025  \n",
       "4      eser contracting and industry co. inc. communi...   35188  \n",
       "...                                                  ...     ...  \n",
       "18972  ah industries corporate social r esponsibility...   39306  \n",
       "18973  1more fit for the future sustainability report...  112118  \n",
       "18974  annual corporate social responsibility report ...   39360  \n",
       "18975  01amatheon agri communication on progress 2017...   21804  \n",
       "18976  24 th october 2014 to our stakeholders i am pl...     586  \n",
       "\n",
       "[18977 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('df_extracted_ranked.csv', engine='python', encoding='utf-8', error_bad_lines=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}