{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvTT3KlRxzWI"
   },
   "source": [
    "## Collecting UN Global Compact Communication of Progress (COP) Annual Reports\n",
    "\n",
    "Web scrapping from [here](https://www.unglobalcompact.org/participation/report/cop/create-and-submit/active) for all COP reports submitted up to 2021. We only take into account the reports submitted in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvHsm_G7xzWL"
   },
   "source": [
    "Please specify below the focus year of this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5WTXJ5OvxzWN"
   },
   "outputs": [],
   "source": [
    "focus_year = \"2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkMkPtN8xzWO"
   },
   "source": [
    "Please select the focus language using one of the following values:\n",
    "- en (English, default option)\n",
    "- de (German)\n",
    "- es (Spanish)\n",
    "- fr (French)\n",
    "- pt (Portuguese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iwc0Qc3gxzWP"
   },
   "outputs": [],
   "source": [
    "focus_language = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hFuJr9_XxzWQ"
   },
   "outputs": [],
   "source": [
    "language_ref = { 'en' : { 'name' : 'English', 'min_coocurrence' : 10},\n",
    "                 'de' : { 'name' : 'German', 'min_coocurrence' : 2},\n",
    "                 'es' : { 'name' : 'Spanish', 'min_coocurrence' : 2},\n",
    "                 'fr' : { 'name' : 'French', 'min_coocurrence' : 2},\n",
    "                 'pt' : { 'name' : 'Portuguese', 'min_coocurrence' : 2},\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2EFtOMWxzWS"
   },
   "source": [
    "## 1. Gather document index information about COP reports available from the website\n",
    "The [UN Global Compact website](https://www.unglobalcompact.org/participation/report/cop/create-and-submit/active) contains entries for each COP report, describing the sector of the company submitting the report, country and year, as well as the language in which the repoort was written in and a link to a PDF file with the full report.\n",
    "\n",
    "**The results in this section give a general view of the available COPs, it's not yet restricted by the focus_year and focus_language.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LMBt2CQi8Hi",
    "outputId": "90afbe4d-4c12-49ff-8d66-9c4d79ae9930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.8/site-packages (21.2.1)\n",
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/lib/python3.8/site-packages (1.26.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (57.4.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: stop-words in /opt/anaconda3/lib/python3.8/site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!python -m pip install PyPDF2\n",
    "!pip install --upgrade setuptools\n",
    "!pip install requests\n",
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gmKAdpY2xzWU"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import shutil\n",
    "import nltk\n",
    "import os\n",
    "import os.path\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZ_0IFaajCOL",
    "outputId": "a9a4d643-b099-4ed5-a031-d70939fdd337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of COPs available: 54594\n"
     ]
    }
   ],
   "source": [
    "#Display the total number of CoPs available\n",
    "\n",
    "gc_url = \"https://www.unglobalcompact.org/participation/report/cop/create-and-submit/active?page=1&per_page=250\"\n",
    "gc_base_url = \"https://www.unglobalcompact.org\"\n",
    "gc_home = requests.get(gc_url)\n",
    "\n",
    "soup = BeautifulSoup(gc_home.content, 'lxml')\n",
    "header = soup.h2.string\n",
    "\n",
    "total_num_cops = re.search(r'(?<=: )[0-9]+', header)[0]\n",
    "print(\"Total number of COPs available: %s\" % total_num_cops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19MVyHRaxzWV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohikendoit/.local/lib/python3.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ohikendoit/opt/anaconda3/lib/python3.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#Create a BeautifulSoup to parse all available HTML page\n",
    "full_gc_url_part1 = \"https://www.unglobalcompact.org/participation/report/cop/create-and-submit/active?page=\"\n",
    "full_gc_url_part2 = \"&per_page=250\"\n",
    "\n",
    "def get_link(page):\n",
    "    \n",
    "    r = requests.get(full_gc_url_part1+str(page)+full_gc_url_part2)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    #links = [td.find_all('a')[0]['href'] for td in soup.find_all('td', 'participant')]\n",
    "\n",
    "    return soup\n",
    "\n",
    "#print(\"Getting full list of reports ...\")\n",
    "gc_full_list_soup=BeautifulSoup()\n",
    "for i in range(0,219): #Current max page; Need to implement len(max page)\n",
    "  gc_full_list_soup.append(get_link(i))\n",
    "\n",
    "#gc_full_list_soup = BeautifulSoup(set_of_links.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FqqxRHgo2l_",
    "outputId": "32a1fa69-2d74-4d68-ed92-d8f882191d0e"
   },
   "outputs": [],
   "source": [
    "#check the existing 'th' class from the soup object\n",
    "#removing of 'th' is required to collect only the gc_full_list_soup.find_all(\"tr\") cell\n",
    "element = gc_full_list_soup.find_all('th')\n",
    "\n",
    "#remove th class\n",
    "for th in gc_full_list_soup('th'):\n",
    "  th.decompose()\n",
    "\n",
    "#remove tags that have no content\n",
    "for x in gc_full_list_soup.find_all():\n",
    "  if len(x.get_text(strip=True)) ==0:\n",
    "    x.extract()\n",
    "\n",
    "#check the results\n",
    "gc_full_list_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dvu160E0xzWb",
    "outputId": "9609eef7-6cbc-4bce-b953-46c4c6b7fb74"
   },
   "outputs": [],
   "source": [
    "#Check SDGs contribution from each company\n",
    "def check_sdgs(profile):\n",
    "    has_sdg1 = \"no\"\n",
    "    has_sdg2 = \"no\"\n",
    "    has_sdg3 = \"no\"\n",
    "    has_sdg4 = \"no\"\n",
    "    has_sdg5 = \"no\"\n",
    "    has_sdg6 = \"no\"\n",
    "    has_sdg7 = \"no\"\n",
    "    has_sdg8 = \"no\"\n",
    "    has_sdg9 = \"no\"\n",
    "    has_sdg10 = \"no\"\n",
    "    has_sdg11 = \"no\"\n",
    "    has_sdg12 = \"no\"\n",
    "    has_sdg13 = \"no\"\n",
    "    has_sdg14 = \"no\"\n",
    "    has_sdg15 = \"no\"\n",
    "    has_sdg16 = \"no\"\n",
    "    has_sdg17 = \"no\"\n",
    "\n",
    "    questions = profile.find_all(\"ul\", class_='questionnaire')\n",
    "    if len(questions) == 2:\n",
    "        sdgs = questions[0].find_all(\"li\")\n",
    "        if len(sdgs) != 18:  # the correct SDG questionnaire has 17 questions + header\n",
    "            temp_sdgs = questions[1].find_all(\"li\")\n",
    "            if len(temp_sdgs) == 18:\n",
    "                sdgs = temp_sdgs\n",
    "            else:\n",
    "                sdgs = []\n",
    "        if 'selected_question' in sdgs[1].get('class'):\n",
    "            has_sdg1 = \"yes\"\n",
    "        if 'selected_question' in sdgs[2].get('class'):\n",
    "            has_sdg2 = \"yes\"\n",
    "        if 'selected_question' in sdgs[3].get('class'):\n",
    "            has_sdg3 = \"yes\"\n",
    "        if 'selected_question' in sdgs[4].get('class'):\n",
    "            has_sdg4 = \"yes\"\n",
    "        if 'selected_question' in sdgs[5].get('class'):\n",
    "            has_sdg5 = \"yes\"\n",
    "        if 'selected_question' in sdgs[6].get('class'):\n",
    "            has_sdg6 = \"yes\"\n",
    "        if 'selected_question' in sdgs[7].get('class'):\n",
    "            has_sdg7 = \"yes\"\n",
    "        if 'selected_question' in sdgs[8].get('class'):\n",
    "            has_sdg8 = \"yes\"\n",
    "        if 'selected_question' in sdgs[9].get('class'):\n",
    "            has_sdg9 = \"yes\"\n",
    "        if 'selected_question' in sdgs[10].get('class'):\n",
    "            has_sdg10 = \"yes\"\n",
    "        if 'selected_question' in sdgs[11].get('class'):\n",
    "            has_sdg11 = \"yes\"\n",
    "        if 'selected_question' in sdgs[12].get('class'):\n",
    "            has_sdg12 = \"yes\"\n",
    "        if 'selected_question' in sdgs[13].get('class'):\n",
    "            has_sdg13 = \"yes\"\n",
    "        if 'selected_question' in sdgs[14].get('class'):\n",
    "            has_sdg14 = \"yes\"\n",
    "        if 'selected_question' in sdgs[15].get('class'):\n",
    "            has_sdg15 = \"yes\"\n",
    "        if 'selected_question' in sdgs[16].get('class'):\n",
    "            has_sdg16 = \"yes\"\n",
    "        if 'selected_question' in sdgs[17].get('class'):\n",
    "            has_sdg17 = \"yes\"\n",
    "\n",
    "          \n",
    "    return (has_sdg1, has_sdg2, has_sdg3, has_sdg4, has_sdg5, has_sdg6, has_sdg7, has_sdg8, has_sdg9, has_sdg10, has_sdg11, has_sdg12,\n",
    "             has_sdg13, has_sdg14, has_sdg15, has_sdg16, has_sdg17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = gc_full_list_soup.find_all(\"tr\")\n",
    "pdfs = {}\n",
    "\n",
    "num_pdfs = 0\n",
    "num_nonpdfs = 0\n",
    "num_noreport = 0\n",
    "\n",
    "langregex = re.compile(r'(?<=\\()[^\\)\\(]+(?=\\)$)')\n",
    "\n",
    "print(\"Getting details of each report ...\")\n",
    "for participant in participants:\n",
    "    cells = participant.find_all('td')\n",
    "    company = cells[0].get_text(strip=True)\n",
    "    sector = cells[1].get_text(strip=True)\n",
    "    country = cells[2].get_text(strip=True)\n",
    "    year = cells[3].get_text(strip=True)\n",
    "\n",
    "    participant_entry_url = gc_base_url + cells[0].a.get('href')\n",
    "    participant_profile = requests.get(participant_entry_url)\n",
    "    participant_profile_soup = BeautifulSoup(participant_profile.content, 'lxml')\n",
    "\n",
    "    (participant_sdgs_1, participant_sdgs_2, participant_sdgs_3, participant_sdgs_4, participant_sdgs_5, participant_sdgs_6, participant_sdgs_7, participant_sdgs_8,\n",
    "     participant_sdgs_9, participant_sdgs_10, participant_sdgs_11, participant_sdgs_12, \n",
    "      participant_sdgs_13, participant_sdgs_14, participant_sdgs_15, participant_sdgs_16, participant_sdgs_17) = check_sdgs(participant_profile_soup)\n",
    "\n",
    "    main_body = participant_profile_soup.find(\"section\", class_='main-content-body')\n",
    "    list_items = main_body.find_all(\"li\")\n",
    "    found_report = False\n",
    "    for li in list_items:\n",
    "        if li.a:\n",
    "            link = li.a.get('href')\n",
    "            if \"/attachments/\" in link:\n",
    "                if \".pdf\" in link:\n",
    "                    link = link.split('?')[0]\n",
    "                    num_pdfs += 1\n",
    "                    language = langregex.search(li.get_text(strip=True))[0]\n",
    "                    pdfs[link] = { \"company\": company, \"sector\" : sector, \"country\" : country, \"year\" : year, \"language\" : language, \"sdgs1\" : participant_sdgs_1, \"sdgs2\" : participant_sdgs_2, \"sdgs3\" : participant_sdgs_3, \"sdgs4\" : participant_sdgs_4,\n",
    "                                  \"sdgs5\" : participant_sdgs_5, \"sdgs6\" : participant_sdgs_6, \"sdgs7\" : participant_sdgs_7, \"sdgs8\" : participant_sdgs_8, \"sdgs9\" : participant_sdgs_9, \"sdgs10\" : participant_sdgs_10,\n",
    "                                  \"sdgs11\" : participant_sdgs_11, \"sdgs12\" : participant_sdgs_12, \"sdgs13\" : participant_sdgs_13, \"sdgs14\" : participant_sdgs_14, \"sdgs15\" : participant_sdgs_15,\n",
    "                                  \"sdgs16\" : participant_sdgs_16, \"sdgs17\" : participant_sdgs_17,}\n",
    "                    print(\".\", end='')\n",
    "                else:\n",
    "                    num_nonpdfs += 1\n",
    "                found_report = True\n",
    "    if not found_report:\n",
    "        num_noreport += 1\n",
    "print(\" done.\")\n",
    "print(\"PDFs: %d, non-PDFs: %d, no-report: %d\" % (num_pdfs, num_nonpdfs, num_noreport))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "S0y17l_5xzWc",
    "outputId": "69474a79-524a-4cae-cf46-fe0ccdd3f3ec"
   },
   "outputs": [],
   "source": [
    "#Saving index of reports so that it can be reused\n",
    "reports_index_csv_filename = \"reports_index.csv\"\n",
    "\n",
    "df_pdfs = pd.DataFrame.from_dict(pdfs, orient='index')\n",
    "df_pdfs.to_csv(reports_index_csv_filename, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T0wdcRnxzWd"
   },
   "source": [
    "\n",
    "---\n",
    "## Starting point if there is already reports_index.csv file\n",
    "This can be used when an index file is available (has been saved previously). Only run this cell if starting from this point, otherwise skip it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPlfLSPkxzWd"
   },
   "outputs": [],
   "source": [
    "#load reports_index\n",
    "reports_index_csv_filename = \"reports_index.csv\"\n",
    "\n",
    "df_pdfs = pd.read_csv(reports_index_csv_filename, sep='\\t', encoding='utf-8', index_col=0, dtype={'year': object})\n",
    "pdfs = df_pdfs.to_dict(orient='index')\n",
    "df_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PsZw2xixzWe"
   },
   "outputs": [],
   "source": [
    "companies = {}\n",
    "countries = {}\n",
    "sectors = {}\n",
    "years = {}\n",
    "languages = {}\n",
    "\n",
    "\n",
    "for pdf in pdfs.keys():\n",
    "    company = pdfs[pdf][\"company\"]\n",
    "    language = pdfs[pdf][\"language\"]\n",
    "    year = pdfs[pdf][\"year\"]\n",
    "    country = pdfs[pdf][\"country\"]\n",
    "    sector = pdfs[pdf][\"sector\"]\n",
    "\n",
    "    companies[company] = companies.get(company,0) + 1\n",
    "    sectors[sector] = sectors.get(sector,0) + 1\n",
    "    countries[country] = countries.get(country,0) + 1\n",
    "    years[year] = years.get(year,0) + 1\n",
    "    languages[language] = languages.get(language,0) + 1    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbwyIRsh8rkM"
   },
   "source": [
    "## 2. Selecting COP reports that match required criteria (up to focus_year, written in focus_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4JAsjID8pc3"
   },
   "outputs": [],
   "source": [
    "selected_companies = {}\n",
    "selected_sectors = {}\n",
    "selected_countries = {}\n",
    "selected_years = {}\n",
    "selected_countries_years = {}\n",
    "\n",
    "selected_pdfs = {}\n",
    "\n",
    "for pdf in pdfs.keys():\n",
    "    company = pdfs[pdf][\"company\"]\n",
    "    language = pdfs[pdf][\"language\"]\n",
    "    year = pdfs[pdf][\"year\"]\n",
    "    country = pdfs[pdf][\"country\"]\n",
    "    sector = pdfs[pdf][\"sector\"]\n",
    "\n",
    "    if language == language_ref[focus_language]['name'] and int(year) <= int(focus_year):\n",
    "        selected_pdfs[pdf] = pdfs[pdf]\n",
    "        \n",
    "        selected_companies[company] = selected_companies.get(company,0) + 1\n",
    "        selected_sectors[sector] = selected_sectors.get(sector,0) + 1\n",
    "        selected_countries[country] = selected_countries.get(country,0) + 1\n",
    "        selected_years[year] = selected_years.get(year,0) + 1\n",
    "        if country in selected_countries_years.keys():\n",
    "            selected_countries_years[country][year] = selected_countries_years[country].get(year,0) + 1\n",
    "        else:\n",
    "            selected_countries_years[country] = {year : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKMTvLMM8poX",
    "outputId": "58d9bc3a-46a7-4a11-c628-576f0a2cc68b"
   },
   "outputs": [],
   "source": [
    "print(\"There are %d reports up to %s written in %s\" % (len(selected_pdfs.keys()), focus_year, language_ref[focus_language]['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjf1w19vxzWn"
   },
   "source": [
    "## 3. Downloading PDF file for each COP report that matches required criteria\n",
    "At this time we've only considered reports written in the focus language and submitted up to end of the focus year.\n",
    "\n",
    "A folder should be specified as the location where PDFs will be downloaded to ('pdfs_folder' variable below).\n",
    "\n",
    "If this process has been run before and some files are already available in the specified folder, they won't be downloaded again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1D36Ds2xzWn"
   },
   "outputs": [],
   "source": [
    "pdfs_folder = \"../data/pdf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "G0zCIA4hxzWn",
    "outputId": "7bf54b94-30c5-417a-ac68-133667799f36"
   },
   "outputs": [],
   "source": [
    "filenameregex = re.compile(r'(?<=/)[^$/]+(?=$)')\n",
    "\n",
    "try:\n",
    "    os.stat(pdfs_folder)\n",
    "except:\n",
    "    os.mkdir(pdfs_folder) \n",
    "\n",
    "for pdf in selected_pdfs.keys():\n",
    "    filename = pdfs_folder + filenameregex.search(pdf)[0]\n",
    "\n",
    "    if not os.path.isfile(filename):\n",
    "        print(\"Saving %s\" % (filename))\n",
    "        file = requests.get('https:'+ pdf, stream=True)\n",
    "        try:\n",
    "            with open(filename, 'wb') as out_file: #file handler needed\n",
    "                shutil.copyfileobj(file.raw, out_file) #file name closed needed\n",
    "            del file\n",
    "        except:\n",
    "            print(\"Could not save %s\" % (filename))\n",
    "            continue\n",
    "        \n",
    "    else:\n",
    "        print(\"Skipping %s, PDF already available in folder\" % (filename))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data_Collection_0_0_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
